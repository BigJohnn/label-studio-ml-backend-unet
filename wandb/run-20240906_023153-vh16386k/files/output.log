[2024-09-06 02:31:55,349] [INFO] [root::train_net::91] Starting training:
        Epochs:          5
        Batch size:      1
        Learning rate:   1e-05
        Training size:   51
        Validation size: 5
        Checkpoints:     True
        Device:          cpu
        Images scaling:  0.5
        Mixed Precision: False
/app/model.py:106: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)
wandb: - Waiting for wandb.init()...:00<?, ?img/s]wandb: | Waiting for wandb.init()...
[2024-09-06 02:31:59,534] [ERROR] [label_studio_ml.api::assertion_error::154] Caught AssertionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataset.py", line 420, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "/app/utils/data_loading.py", line 75, in __getitem__
    assert img.size == mask.size, \
           ^^^^^^^^^^^^^^^^^^^^^
AssertionError: Image and mask {name} should be the same size, but are {img.size} and {mask.size}
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/label_studio_ml/api.py", line 126, in webhook
    model.fit(event, data)
  File "/app/model.py", line 393, in fit
    train_net(images,masks,net,device)
  File "/app/model.py", line 115, in train_net
    for batch in train_loader:
                 ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
    data.reraise()
  File "/usr/local/lib/python3.12/site-packages/torch/_utils.py", line 706, in reraise
    raise exception
AssertionError: Caught AssertionError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py", line 50, in fetch
    data = self.dataset.__getitems__(possibly_batched_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataset.py", line 420, in __getitems__
    return [self.dataset[self.indices[idx]] for idx in indices]
            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "/app/utils/data_loading.py", line 75, in __getitem__
    assert img.size == mask.size, \
           ^^^^^^^^^^^^^^^^^^^^^
AssertionError: Image and mask {name} should be the same size, but are {img.size} and {mask.size}
[2024-09-06 02:31:59,535] [DEBUG] [label_studio_ml.api::log_response_info::185] Response status: 500 INTERNAL SERVER ERROR
[2024-09-06 02:31:59,535] [DEBUG] [label_studio_ml.api::log_response_info::186] Response headers: Content-Type: text/html; charset=utf-8
Content-Length: 971

Epoch 1/5:   0%|          | 0/51 [00:04<?, ?img/s]wandb: | Waiting for wandb.init()...







wandb: | Waiting for wandb.init()...
[2024-09-06 02:32:16,396] [DEBUG] [urllib3.connectionpool::_new_conn::1051] Starting new HTTPS connection (1): o151352.ingest.sentry.io:443















wandb: - Waiting for wandb.init()...
[2024-09-06 02:32:46,973] [DEBUG] [urllib3.connectionpool::_make_request::546] https://o151352.ingest.sentry.io:443 "POST /api/4504800232407040/envelope/ HTTP/11" 200 0
[2024-09-06 02:32:46,974] [ERROR] [label_studio_ml.api::log_exception::1414] Exception on /webhook [POST]
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/label_studio_ml/api.py", line 126, in webhook
    model.fit(event, data)
  File "/app/model.py", line 393, in fit
    train_net(images,masks,net,device)
  File "/app/model.py", line 86, in train_net
    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 1243, in init
    wandb._sentry.reraise(e)
  File "/usr/local/lib/python3.12/site-packages/wandb/analytics/sentry.py", line 155, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 1229, in init
    return wi.init()
           ^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 833, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec.
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
[2024-09-06 02:32:46,978] [DEBUG] [label_studio_ml.api::log_response_info::185] Response status: 500 INTERNAL SERVER ERROR
[2024-09-06 02:32:46,978] [DEBUG] [label_studio_ml.api::log_response_info::186] Response headers: Content-Type: text/html; charset=utf-8
Content-Length: 265
[2024-09-06 02:32:46,979] [DEBUG] [label_studio_ml.api::log_response_info::187] Response body: b'<!doctype html>\n<html lang=en>\n<title>500 Internal Server Error</title>\n<h1>Internal Server Error</h1>\n<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n'
[2024-09-06 02:32:47,368] [DEBUG] [urllib3.connectionpool::_make_request::546] https://o151352.ingest.sentry.io:443 "POST /api/4504800232407040/envelope/ HTTP/11" 200 0
[2024-09-06 02:32:47,369] [ERROR] [label_studio_ml.api::log_exception::1414] Exception on /webhook [POST]
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 2190, in wsgi_app
    response = self.full_dispatch_request()
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1486, in full_dispatch_request
    rv = self.handle_user_exception(e)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/flask/app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/label_studio_ml/api.py", line 126, in webhook
    model.fit(event, data)
  File "/app/model.py", line 393, in fit
    train_net(images,masks,net,device)
  File "/app/model.py", line 86, in train_net
    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 1243, in init
    wandb._sentry.reraise(e)
  File "/usr/local/lib/python3.12/site-packages/wandb/analytics/sentry.py", line 155, in reraise
    raise exc.with_traceback(sys.exc_info()[2])
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 1229, in init
    return wi.init()
           ^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/wandb/sdk/wandb_init.py", line 833, in init
    raise error
wandb.errors.CommError: Run initialization has timed out after 90.0 sec.
Please refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-
[2024-09-06 02:32:47,374] [DEBUG] [label_studio_ml.api::log_response_info::185] Response status: 500 INTERNAL SERVER ERROR
[2024-09-06 02:32:47,374] [DEBUG] [label_studio_ml.api::log_response_info::186] Response headers: Content-Type: text/html; charset=utf-8
Content-Length: 265
